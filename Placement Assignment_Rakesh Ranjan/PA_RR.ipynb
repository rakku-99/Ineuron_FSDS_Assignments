{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS ASSESSMENT "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1.:\n",
    "\n",
    "Write a program that takes a string as input, and counts the frequency of each word in the string, there might\n",
    "be repeated characters in the string. Your task is to find the highest frequency and returns the length of the\n",
    "highest-frequency word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent_word_length(string):\n",
    "    word_freq = {}\n",
    "    words = string.split()\n",
    "    \n",
    "    for word in words:\n",
    "        word_freq[word] = word_freq.get(word, 0) + 1\n",
    "    \n",
    "    max_freq = max(word_freq.values())\n",
    "    \n",
    "    max_length = max(len(word) for word, freq in word_freq.items() if freq == max_freq)\n",
    "    \n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "string1 = \"apple shake banana apple apple shake cherry apple banana apple apple\"\n",
    "string2 = \"a a a a a b b c c d d d e e e e\"\n",
    "print(most_frequent_word_length(string1))\n",
    "print(most_frequent_word_length(string2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In additional test case 1, \n",
    "the word \"apple\" has the highest frequency of 6. \n",
    "The length of the highest-frequency word \"apple\" is 5.\n",
    "\n",
    "In additional test case 2, \n",
    "the word \"a\" has the highest frequency of 5\n",
    "The length of the highest-frequency word \"a\" is 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2.:\n",
    "\n",
    "Consider a string to be valid if all characters of the string appear the same number of times. \n",
    "It is also valid if he can remove just one character at the index in the string, and the remaining \n",
    "characters will occur the same number of times. Given a string, determine if it is valid. \n",
    "If so, return YES , otherwise return NO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_string_validity(string):\n",
    "    char_freq = {}\n",
    "    \n",
    "    # Count the frequency of each character\n",
    "    for char in string:\n",
    "        char_freq[char] = char_freq.get(char, 0) + 1\n",
    "    \n",
    "    freq_values = list(char_freq.values())\n",
    "    distinct_freq = set(freq_values)\n",
    "    \n",
    "    if len(distinct_freq) == 1:\n",
    "        # All characters have the same frequency\n",
    "        return \"YES\"\n",
    "    elif len(distinct_freq) == 2:\n",
    "        # Check if removing one character makes the frequencies the same\n",
    "        freq_count = {}\n",
    "        \n",
    "        for freq in freq_values:\n",
    "            freq_count[freq] = freq_count.get(freq, 0) + 1\n",
    "        \n",
    "        if 1 in freq_count.values() and freq_count.get(1, 0) == 1:\n",
    "            # Removing one occurrence of a character makes frequencies the same\n",
    "            return \"YES\"\n",
    "    \n",
    "    # String is not valid\n",
    "    return \"NO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "YES\n"
     ]
    }
   ],
   "source": [
    "# Additional test case 1\n",
    "s = \"aabbcc\"\n",
    "print(check_string_validity(s))\n",
    "# Output: YES\n",
    "# Explanation: All characters have the same frequency (2).\n",
    "\n",
    "# Additional test case 2\n",
    "s = \"aabbccd\"\n",
    "print(check_string_validity(s))\n",
    "# Output: YES\n",
    "# Explanation: Removing one occurrence of \"d\" makes the frequencies the same:\n",
    "# {\"a\": 2, \"b\": 2, \"c\": 2}."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In additional test case 1, all characters have the same frequency (2), so the string is valid.\n",
    "\n",
    "In additional test case 2, removing one occurrence of \"d\" makes the frequencies of all characters the same: {\"a\": 2, \"b\": 2, \"c\": 2}. Thus, the string is valid."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 3.:\n",
    "\n",
    "Write a program, which would download the data from the provided link, and then read the data and convert that into properly structured data and return it in Excel format.\n",
    "Note - Write comments wherever necessary explaining the code written.\n",
    "\n",
    "Link - https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\n",
    "\n",
    "Data Attributes - \n",
    "\n",
    "●\tid: Identification Number - int \n",
    "\n",
    "●\tnum: Number of the Pokémon in the official Pokédex - int \n",
    "\n",
    "●\tname: Pokémon name - string \n",
    "\n",
    "●\timg: URL to an image of this Pokémon - string \n",
    "\n",
    "●\ttype: Pokémon type -string \n",
    "\n",
    "●\theight: Pokémon height - float\n",
    "\n",
    "●\tweight: Pokémon weight - float \n",
    "\n",
    "●\tcandy: type of candy used to evolve Pokémon or given when transferred - string \n",
    "\n",
    "●\tcandy_count: the amount of candies required to evolve - int\n",
    "●\tegg: Number of kilometers to travel to hatch the egg - float \n",
    "\n",
    "●\tspawn_chance: Percentage of spawn chance (NEW) - float \n",
    "\n",
    "●\tavg_spawns: Number of this pokemon on 10.000 spawns (NEW) - int\n",
    "\n",
    "●\tspawn_time: Spawns most active at the time on this field. Spawn times are the same for all time zones and are expressed in local time. (NEW) - “minutes: seconds” \n",
    "\n",
    "●\tmultipliers: Multiplier of Combat Power (CP) for calculating the CP after evolution See below - list of int \n",
    "\n",
    "●\tweakness: Types of\tPokémon this Pokémon is weak to - list of strings \n",
    "\n",
    "●\tnext_evolution: Number and Name of successive evolutions of Pokémon - list of dict \n",
    "\n",
    "●\tprev_evolution: Number and Name of previous evolutions of Pokémon - list of dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 70\u001b[0m\n\u001b[0;32m     66\u001b[0m data \u001b[39m=\u001b[39m to_download_data(url)\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[39m# Process the downloaded data\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     structured_data \u001b[39m=\u001b[39m to_process_data(data)\n\u001b[0;32m     72\u001b[0m     \u001b[39m# Save structured data to Excel file\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     to_save_to_excel(structured_data, \u001b[39m\"\u001b[39m\u001b[39mpokemon_data.xlsx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m, in \u001b[0;36mto_process_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     14\u001b[0m structured_data \u001b[39m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m pokemon \u001b[39min\u001b[39;00m data[\u001b[39m\"\u001b[39m\u001b[39mpokemon\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m     17\u001b[0m     pokemon_info \u001b[39m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: pokemon[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     19\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m\"\u001b[39m: pokemon[\u001b[39m\"\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     20\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: pokemon[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     21\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m: pokemon[\u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     22\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(pokemon[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[0;32m     23\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m\"\u001b[39m: pokemon[\u001b[39m\"\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     24\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m: pokemon[\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     25\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcandy\u001b[39m\u001b[39m\"\u001b[39m: pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcandy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     26\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcandy_count\u001b[39m\u001b[39m\"\u001b[39m: pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcandy_count\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[0;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39megg\u001b[39m\u001b[39m\"\u001b[39m: pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39megg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     28\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspawn_chance\u001b[39m\u001b[39m\"\u001b[39m: pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mspawn_chance\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[0;32m     29\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mavg_spawns\u001b[39m\u001b[39m\"\u001b[39m: pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mavg_spawns\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[0;32m     30\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspawn_time\u001b[39m\u001b[39m\"\u001b[39m: pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mspawn_time\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m---> 31\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultipliers\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(multiplier) \u001b[39mfor\u001b[39;00m multiplier \u001b[39min\u001b[39;00m pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmultipliers\u001b[39m\u001b[39m\"\u001b[39m, [])),\n\u001b[0;32m     32\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mweakness\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mweaknesses\u001b[39m\u001b[39m\"\u001b[39m, []))\n\u001b[0;32m     33\u001b[0m     }\n\u001b[0;32m     35\u001b[0m     next_evolution \u001b[39m=\u001b[39m pokemon\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnext_evolution\u001b[39m\u001b[39m\"\u001b[39m, [])\n\u001b[0;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m next_evolution:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "\n",
    "def to_download_data(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def to_process_data(data):\n",
    "    structured_data = []\n",
    "    \n",
    "    for pokemon in data[\"pokemon\"]:\n",
    "        pokemon_info = {\n",
    "            \"id\": pokemon[\"id\"],\n",
    "            \"num\": pokemon[\"num\"],\n",
    "            \"name\": pokemon[\"name\"],\n",
    "            \"img\": pokemon[\"img\"],\n",
    "            \"type\": \", \".join(pokemon[\"type\"]),\n",
    "            \"height\": pokemon[\"height\"],\n",
    "            \"weight\": pokemon[\"weight\"],\n",
    "            \"candy\": pokemon.get(\"candy\", \"\"),\n",
    "            \"candy_count\": pokemon.get(\"candy_count\", 0),\n",
    "            \"egg\": pokemon.get(\"egg\", \"\"),\n",
    "            \"spawn_chance\": pokemon.get(\"spawn_chance\", 0),\n",
    "            \"avg_spawns\": pokemon.get(\"avg_spawns\", 0),\n",
    "            \"spawn_time\": pokemon.get(\"spawn_time\", \"\"),\n",
    "            \"multipliers\": \", \".join(str(multiplier) for multiplier in pokemon.get(\"multipliers\", [])),\n",
    "            \"weakness\": \", \".join(pokemon.get(\"weaknesses\", []))\n",
    "        }\n",
    "        \n",
    "        next_evolution = pokemon.get(\"next_evolution\", [])\n",
    "        if next_evolution:\n",
    "            pokemon_info[\"next_evolution\"] = \", \".join(evol[\"name\"] for evol in next_evolution)\n",
    "        else:\n",
    "            pokemon_info[\"next_evolution\"] = \"\"\n",
    "        \n",
    "        prev_evolution = pokemon.get(\"prev_evolution\", [])\n",
    "        if prev_evolution:\n",
    "            pokemon_info[\"prev_evolution\"] = \", \".join(evol[\"name\"] for evol in prev_evolution)\n",
    "        else:\n",
    "            pokemon_info[\"prev_evolution\"] = \"\"\n",
    "        \n",
    "        structured_data.append(pokemon_info)\n",
    "    \n",
    "    return structured_data\n",
    "\n",
    "def to_save_to_excel(data, filename):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    \n",
    "    headers = list(data[0].keys())\n",
    "    ws.append(headers)\n",
    "    \n",
    "    for pokemon in data:\n",
    "        row_data = list(pokemon.values())\n",
    "        ws.append(row_data)\n",
    "    \n",
    "    wb.save(filename)\n",
    "\n",
    "# Download data from the provided link\n",
    "url = \"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\"\n",
    "data = to_download_data(url)\n",
    "\n",
    "if data is not None:\n",
    "    # Process the downloaded data\n",
    "    structured_data = to_process_data(data)\n",
    "    \n",
    "    # Save structured data to Excel file\n",
    "    to_save_to_excel(structured_data, \"pokemon_data.xlsx\")\n",
    "    print(\"Data saved successfully to 'pokemon_data.xlsx'\")\n",
    "else:\n",
    "    print(\"Failed to download data from the provided link.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_download_data(url):\n",
    "    response = requests.get(url)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_process_data(data):\n",
    "    structured_data = []\n",
    "    \n",
    "    for pokemon in data[\"pokemon\"]:\n",
    "        pokemon_info = {\n",
    "            \"id\": pokemon[\"id\"],\n",
    "            \"num\": pokemon[\"num\"],\n",
    "            \"name\": pokemon[\"name\"],\n",
    "            \"img\": pokemon[\"img\"],\n",
    "            \"type\": \", \".join(pokemon[\"type\"]),\n",
    "            \"height\": pokemon[\"height\"],\n",
    "            \"weight\": pokemon[\"weight\"],\n",
    "            \"candy\": pokemon.get(\"candy\", \"\"),\n",
    "            \"candy_count\": pokemon.get(\"candy_count\", 0),\n",
    "            \"egg\": pokemon.get(\"egg\", \"\"),\n",
    "            \"spawn_chance\": pokemon.get(\"spawn_chance\", 0),\n",
    "            \"avg_spawns\": pokemon.get(\"avg_spawns\", 0),\n",
    "            \"spawn_time\": pokemon.get(\"spawn_time\", \"\"),\n",
    "            \"multipliers\": \", \".join(str(multiplier) for multiplier in pokemon.get(\"multipliers\", [])),\n",
    "            \"weakness\": \", \".join(pokemon.get(\"weaknesses\", []))\n",
    "        }\n",
    "        \n",
    "        next_evolution = pokemon.get(\"next_evolution\", [])\n",
    "        if next_evolution:\n",
    "            pokemon_info[\"next_evolution\"] = \", \".join(evol[\"name\"] for evol in next_evolution)\n",
    "        else:\n",
    "            pokemon_info[\"next_evolution\"] = \"\"\n",
    "        \n",
    "        prev_evolution = pokemon.get(\"prev_evolution\", [])\n",
    "        if prev_evolution:\n",
    "            pokemon_info[\"prev_evolution\"] = \", \".join(evol[\"name\"] for evol in prev_evolution)\n",
    "        else:\n",
    "            pokemon_info[\"prev_evolution\"] = \"\"\n",
    "        \n",
    "        structured_data.append(pokemon_info)\n",
    "    \n",
    "    return structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from the provided link\n",
    "url = \"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\"\n",
    "data = to_download_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json')\n",
    "df.to_excel('pokemon.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 4.:\n",
    "\n",
    "Write a program to download the data from the link given below and then read the data and convert the into\n",
    "the proper structure and return it as a CSV file.\n",
    "\n",
    "Link - https://data.nasa.gov/resource/y77d-th95.json\n",
    "\n",
    "Note - Write code comments wherever needed for code understanding.\n",
    "\n",
    "Excepted Output Data Attributes\n",
    "\n",
    "● Name of Earth Meteorite - string \n",
    "\n",
    "● id - ID of Earth\n",
    "\n",
    "● Meteorite - int \n",
    "\n",
    "● nametype - string \n",
    "\n",
    "● recclass - string\n",
    "\n",
    "● mass - Mass of Earth Meteorite - float \n",
    "\n",
    "● year - Year at which Earth\n",
    "● Meteorite was hit - datetime format \n",
    "\n",
    "● reclat - float recclong - float\n",
    "\n",
    "● point coordinates - list of int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Download the JSON data from the URL\n",
    "url = \"https://data.nasa.gov/resource/y77d-th95.json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the desired output data attributes\n",
    "output_attributes = [\n",
    "    \"name\",\n",
    "    \"id\",\n",
    "    \"nametype\",\n",
    "    \"recclass\",\n",
    "    \"mass (g)\",\n",
    "    \"year\",\n",
    "    \"reclat\",\n",
    "    \"reclong\",\n",
    "]\n",
    "\n",
    "# Select only the desired attributes from the DataFrame\n",
    "df = df[output_attributes]\n",
    "\n",
    "# Rename the columns to match the expected output data attributes\n",
    "column_names = {\n",
    "    \"name\": \"Name of Earth Meteorite\",\n",
    "    \"id\": \"ID of Earth Meteorite\",\n",
    "    \"nametype\": \"Meteorite\",\n",
    "    \"recclass\": \"Meteorite Class\",\n",
    "    \"mass (g)\": \"Mass of Earth Meteorite\",\n",
    "    \"year\": \"Year\",\n",
    "    \"reclat\": \"Latitude\",\n",
    "    \"reclong\": \"Longitude\",\n",
    "}\n",
    "df = df.rename(columns=column_names)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "output_file = \"earth_meteorites.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data saved as {output_file}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 5.:\n",
    "\n",
    "Write a program to download the data from the given API link and then extract the following data with\n",
    "proper formatting\n",
    "\n",
    "Link - http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\n",
    "\n",
    "Note - Write proper code comments wherever needed for the code understanding\n",
    "\n",
    "Excepted Output Data Attributes -\n",
    "\n",
    "● id - int url - string\n",
    "\n",
    "● name - string \n",
    "\n",
    "● season - int \n",
    "\n",
    "● number - int\n",
    "\n",
    "● type - string \n",
    "\n",
    "● airdate - date format \n",
    "\n",
    "● airtime - 12-hour time format\n",
    "\n",
    "● runtime - float\n",
    "\n",
    "● average rating - float\n",
    "\n",
    "● summary - string without html tags\n",
    "\n",
    "● medium image link - string\n",
    "\n",
    "● Original image link - string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download the data from the API\n",
    "url = \"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Extract the desired data attributes\n",
    "show_id = data[\"id\"]\n",
    "show_url = data[\"url\"]\n",
    "show_name = data[\"name\"]\n",
    "episodes = data[\"_embedded\"][\"episodes\"]\n",
    "\n",
    "# Format and print the extracted data for each episode\n",
    "for episode in episodes:\n",
    "    episode_id = episode[\"id\"]\n",
    "    episode_season = episode[\"season\"]\n",
    "    episode_number = episode[\"number\"]\n",
    "    episode_type = episode[\"type\"]\n",
    "    episode_airdate = episode[\"airdate\"]\n",
    "    episode_airtime = episode[\"airtime\"]\n",
    "    episode_runtime = episode[\"runtime\"]\n",
    "    episode_rating = episode[\"rating\"][\"average\"]\n",
    "    episode_summary = episode[\"summary\"]\n",
    "    episode_image_medium = episode[\"image\"][\"medium\"]\n",
    "    episode_image_original = episode[\"image\"][\"original\"]\n",
    "\n",
    "    # Format the airtime to 12-hour time format\n",
    "    formatted_airtime = None\n",
    "    if episode_airtime:\n",
    "        formatted_airtime = pd.to_datetime(episode_airtime).strftime(\"%I:%M %p\")\n",
    "\n",
    "    # Print the extracted data for the episode\n",
    "    print(f\"Episode ID: {episode_id}\")\n",
    "    print(f\"Show ID: {show_id}\")\n",
    "    print(f\"Show URL: {show_url}\")\n",
    "    print(f\"Show Name: {show_name}\")\n",
    "    print(f\"Season: {episode_season}\")\n",
    "    print(f\"Number: {episode_number}\")\n",
    "    print(f\"Type: {episode_type}\")\n",
    "    print(f\"Airdate: {episode_airdate}\")\n",
    "    print(f\"Airtime: {formatted_airtime}\")\n",
    "    print(f\"Runtime: {episode_runtime} minutes\")\n",
    "    print(f\"Average Rating: {episode_rating}\")\n",
    "    print(f\"Summary: {episode_summary}\")\n",
    "    print(f\"Medium Image Link: {episode_image_medium}\")\n",
    "    print(f\"Original Image Link: {episode_image_original}\")\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 6.:\n",
    "\n",
    "Using the data from Question 3, write code to analyze the data and answer the following questions \n",
    "\n",
    "Note 1.Draw plots to demonstrate the analysis for the following questions for better visualizations.\n",
    "\n",
    "2. Write code comments wherever required for code understanding\n",
    "\n",
    "Insights to be drawn -\n",
    "● Get all Pokemons whose spawn rate is less than 5%\n",
    "\n",
    "● Get all Pokemons that have less than 4 weaknesses\n",
    "\n",
    "● Get all Pokemons that have no multipliers at all\n",
    "\n",
    "● Get all Pokemons that do not have more than 2 evolutions\n",
    "\n",
    "● Get all Pokemons whose spawn time is less than 300 seconds.\n",
    "\n",
    "Note - spawn time format is \"05:32”, so assume “minute: second” format and perform the analysis.\n",
    "\n",
    "● Get all Pokemon who have more than two types of capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download the data from the URL\n",
    "url = \"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Create a DataFrame from the Pokémon data\n",
    "df = pd.DataFrame(data['pokemon'])\n",
    "\n",
    "# Question 1: Get all Pokémon whose spawn rate is less than 5%\n",
    "\n",
    "# Convert the 'spawn_chance' column to numeric\n",
    "df['spawn_chance'] = pd.to_numeric(df['spawn_chance'], errors='coerce')\n",
    "\n",
    "# Filter Pokémon with spawn rate less than 5%\n",
    "pokemon_low_spawn_rate = df[df['spawn_chance'] < 5]\n",
    "\n",
    "print(\"Pokémon with Spawn Rate Less Than 5%:\")\n",
    "print(pokemon_low_spawn_rate)\n",
    "\n",
    "# Question 2: Get all Pokémon that have less than 4 weaknesses\n",
    "\n",
    "# Convert the 'weaknesses' column to a count of weaknesses\n",
    "df['weaknesses_count'] = df['weaknesses'].apply(lambda x: len(x))\n",
    "\n",
    "# Filter Pokémon with less than 4 weaknesses\n",
    "pokemon_few_weaknesses = df[df['weaknesses_count'] < 4]\n",
    "\n",
    "print(\"\\nPokémon with Less Than 4 Weaknesses:\")\n",
    "print(pokemon_few_weaknesses)\n",
    "\n",
    "# Question 3: Get all Pokémon that have no multipliers at all\n",
    "\n",
    "# Filter Pokémon with no multipliers\n",
    "pokemon_no_multipliers = df[df['multipliers'].apply(lambda x: len(x) == 0)]\n",
    "\n",
    "print(\"\\nPokémon with No Multipliers:\")\n",
    "print(pokemon_no_multipliers)\n",
    "\n",
    "# Question 4: Get all Pokémon that do not have more than 2 evolutions\n",
    "\n",
    "# Convert the 'next_evolution' column to a count of evolutions\n",
    "df['evolution_count'] = df['next_evolution'].apply(lambda x: len(x) if x else 0)\n",
    "\n",
    "# Filter Pokémon with not more than 2 evolutions\n",
    "pokemon_few_evolutions = df[df['evolution_count'] <= 2]\n",
    "\n",
    "print(\"\\nPokémon with Not More Than 2 Evolutions:\")\n",
    "print(pokemon_few_evolutions)\n",
    "\n",
    "# Question 5: Get all Pokémon whose spawn time is less than 300 seconds\n",
    "\n",
    "# Convert the 'spawn_time' column to seconds\n",
    "df['spawn_seconds'] = df['spawn_time'].apply(lambda x: int(x.split(':')[0]) * 60 + int(x.split(':')[1]))\n",
    "\n",
    "# Filter Pokémon with spawn time less than 300 seconds\n",
    "pokemon_low_spawn_time = df[df['spawn_seconds'] < 300]\n",
    "\n",
    "print(\"\\nPokémon with Spawn Time Less Than 300 Seconds:\")\n",
    "print(pokemon_low_spawn_time)\n",
    "\n",
    "# Question 6: Get all Pokémon who have more than two types of capabilities\n",
    "\n",
    "# Convert the 'type' column to a count of types\n",
    "df['type_count'] = df['type'].apply(lambda x: len(x))\n",
    "\n",
    "# Filter Pokémon with more than two types\n",
    "pokemon_multiple_types = df[df['type_count'] > 2]\n",
    "\n",
    "print(\"\\nPokémon with More Than Two Types of Capabilities:\")\n",
    "print(pokemon_multiple_types)\n",
    "\n",
    "# Plotting the distribution of Pokémon spawn rates\n",
    "plt.hist(df['spawn_chance'], bins=20)\n",
    "plt.title('Distribution of Pokémon Spawn Rates')\n",
    "plt.xlabel('Spawn Rate (%)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program uses the data from the provided URL and performs various analyses on the Pokémon data. It uses pandas for data manipulation, matplotlib for plotting, and string operations to handle different data formats.\n",
    "\n",
    "Here are the insights drawn for each question:\n",
    "\n",
    "The program filters and displays all the Pokémon with a spawn rate less than 5%.\n",
    "\n",
    "The program filters and displays all the Pokémon with less than 4 weaknesses.\n",
    "\n",
    "The program filters and displays all the Pokémon with no multipliers.\n",
    "\n",
    "The program filters and displays all the Pokémon with not more than 2 evolutions.\n",
    "\n",
    "The program filters and displays all the Pokémon with a spawn time less than 300 seconds. It converts the spawn time format from \"minute:second\" to seconds for analysis.\n",
    "\n",
    "The program filters and displays all the Pokémon with more than two types of capabilities.\n",
    "\n",
    "Additionally, the program includes a histogram plot to visualize the distribution of Pokémon spawn rates.\n",
    "\n",
    "These insights provide information about the rarity, strengths, evolution patterns, spawn timing, and variety of capabilities among different Pokémon species."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 7.:\n",
    "\n",
    "Using the data from Question 4, write code to analyze the data and answer the following questions \n",
    "\n",
    "Note - 1. Draw plots to demonstrate the analysis for the following questions for better visualizations\n",
    "\n",
    "2. Write code comments wherever required for code understanding\n",
    "\n",
    "Insights to be drawn -\n",
    "\n",
    "● Get all the Earth meteorites that fell before the year 2000\n",
    "\n",
    "● Get all the earth meteorites co-ordinates who fell before the year 1970\n",
    "\n",
    "● Assuming that the mass of the earth meteorites was in kg, get all those whose mass was more than 10000kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download the data from the API\n",
    "url = \"https://data.nasa.gov/resource/y77d-th95.json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Create a DataFrame from the meteorites data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Question 1: Get all the Earth meteorites that fell before the year 2000\n",
    "\n",
    "# Convert the 'year' column to datetime format\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "\n",
    "# Filter meteorites that fell before the year 2000\n",
    "meteorites_before_2000 = df[df['year'] < '2000-01-01']\n",
    "\n",
    "print(\"Earth Meteorites That Fell Before the Year 2000:\")\n",
    "print(meteorites_before_2000)\n",
    "\n",
    "# Question 2: Get all the Earth meteorites coordinates that fell before the year 1970\n",
    "\n",
    "# Filter meteorites that fell before the year 1970\n",
    "meteorites_before_1970 = df[df['year'] < '1970-01-01']\n",
    "\n",
    "# Convert the 'reclat' and 'reclong' columns to numeric\n",
    "meteorites_before_1970['reclat'] = pd.to_numeric(meteorites_before_1970['reclat'], errors='coerce')\n",
    "meteorites_before_1970['reclong'] = pd.to_numeric(meteorites_before_1970['reclong'], errors='coerce')\n",
    "\n",
    "# Filter out rows with missing coordinate values\n",
    "meteorites_with_coordinates = meteorites_before_1970.dropna(subset=['reclat', 'reclong'])\n",
    "\n",
    "print(\"\\nEarth Meteorites Coordinates That Fell Before the Year 1970:\")\n",
    "print(meteorites_with_coordinates[['reclat', 'reclong']])\n",
    "\n",
    "# Question 3: Get all Earth meteorites with mass greater than 10000 kg\n",
    "\n",
    "# Convert the 'mass' column to numeric\n",
    "df['mass'] = pd.to_numeric(df['mass'], errors='coerce')\n",
    "\n",
    "# Filter meteorites with mass greater than 10000 kg\n",
    "meteorites_gt_10000kg = df[df['mass'] > 10000]\n",
    "\n",
    "print(\"\\nEarth Meteorites with Mass Greater Than 10000 kg:\")\n",
    "print(meteorites_gt_10000kg)\n",
    "\n",
    "# Plotting the distribution of meteorite masses\n",
    "plt.hist(df['mass'], bins=50)\n",
    "plt.title('Distribution of Meteorite Masses')\n",
    "plt.xlabel('Mass (kg)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program uses the data from the provided API link and performs various analyses on the Earth meteorites. It uses pandas for data manipulation, matplotlib for plotting, and datetime functions to handle date-related operations.\n",
    "\n",
    "Here are the insights drawn for each question:\n",
    "\n",
    "The program filters and displays all the Earth meteorites that fell before the year 2000.\n",
    "\n",
    "The program filters and displays the coordinates of Earth meteorites that fell before the year 1970. It also handles missing or invalid coordinate values.\n",
    "\n",
    "The program filters and displays all the Earth meteorites with a mass greater than 10000 kg. It also includes a histogram plot to visualize the distribution of meteorite masses.\n",
    "\n",
    "These insights provide information about the timing of meteorite falls, their geographic locations, and the mass distribution of Earth meteorites."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 8.:\n",
    "\n",
    "Using the data from Question 5, write code the analyze the data and answer the following questions \n",
    "\n",
    "Note - 1. Draw plots to demonstrate the analysis for the following questions and better visualizations\n",
    "\n",
    "2. Write code comments wherever required for code understanding\n",
    "\n",
    "Insights to be drawn -\n",
    "\n",
    "● Get all the overall ratings for each season and using plots compare the ratings for all the seasons, like season 1 ratings, season 2, and so on.\n",
    "\n",
    "● Get all the episode names, whose average rating is more than 8 for every season\n",
    "\n",
    "● Get all the episode names that aired before May 2019\n",
    "\n",
    "● Get the episode name from each season with the highest and lowest rating\n",
    "\n",
    "● Get the summary for the most popular ( ratings ) episode in every season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download the data from the API\n",
    "url = \"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Extract the episodes data\n",
    "episodes = data[\"_embedded\"][\"episodes\"]\n",
    "\n",
    "# Create a DataFrame from the episodes data\n",
    "df = pd.DataFrame(episodes)\n",
    "\n",
    "# Clean and preprocess the DataFrame\n",
    "df['airdate'] = pd.to_datetime(df['airdate'])  # Convert airdate to datetime format\n",
    "df['season'] = df['season'].astype(int)  # Convert season to integer\n",
    "\n",
    "# Question 1: Get all the overall ratings for each season and compare ratings using plots\n",
    "\n",
    "# Group the episodes by season and calculate the average rating\n",
    "season_ratings = df.groupby('season')['rating'].mean()\n",
    "\n",
    "# Plot the ratings for each season\n",
    "season_ratings.plot(kind='bar', figsize=(8, 6))\n",
    "plt.title('Average Ratings for Each Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.show()\n",
    "\n",
    "# Question 2: Get all the episode names with average rating > 8 for each season\n",
    "\n",
    "# Filter episodes with average rating > 8 for each season\n",
    "high_rating_episodes = df.groupby(['season', 'name'])['rating'].mean().reset_index()\n",
    "high_rating_episodes = high_rating_episodes[high_rating_episodes['rating'] > 8]\n",
    "\n",
    "print(\"\\nEpisode Names with Average Rating > 8 for Each Season:\")\n",
    "print(high_rating_episodes[['season', 'name']])\n",
    "\n",
    "# Question 3: Get episode names that aired before May 2019\n",
    "\n",
    "# Filter episodes that aired before May 2019\n",
    "episodes_before_2019 = df[df['airdate'] < '2019-05-01']\n",
    "\n",
    "print(\"\\nEpisode Names Aired Before May 2019:\")\n",
    "print(episodes_before_2019['name'])\n",
    "\n",
    "# Question 4: Get episode name with the highest and lowest rating for each season\n",
    "\n",
    "# Get episode with highest rating for each season\n",
    "highest_rating_episodes = df.groupby('season').apply(lambda x: x.loc[x['rating'].idxmax()])\n",
    "\n",
    "# Get episode with lowest rating for each season\n",
    "lowest_rating_episodes = df.groupby('season').apply(lambda x: x.loc[x['rating'].idxmin()])\n",
    "\n",
    "print(\"\\nEpisode Name with Highest Rating for Each Season:\")\n",
    "print(highest_rating_episodes[['season', 'name', 'rating']])\n",
    "\n",
    "print(\"\\nEpisode Name with Lowest Rating for Each Season:\")\n",
    "print(lowest_rating_episodes[['season', 'name', 'rating']])\n",
    "\n",
    "# Question 5: Get the summary for the most popular (highest ratings) episode in every season\n",
    "\n",
    "# Get the most popular episode (highest ratings) for each season\n",
    "most_popular_episodes = df.groupby('season').apply(lambda x: x.loc[x['rating'].idxmax()])\n",
    "\n",
    "print(\"\\nSummary for the Most Popular Episode in Every Season:\")\n",
    "print(most_popular_episodes[['season', 'name', 'summary']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program uses the data from the provided API link and performs various analyses on the TV show episodes. It uses pandas for data manipulation, matplotlib for plotting, and datetime functions to handle date-related operations.\n",
    "\n",
    "Here are the insights drawn for each question:\n",
    "\n",
    "The program calculates the average ratings for each season and visualizes them using a bar plot.\n",
    "\n",
    "The program filters and displays the episode names with an average rating greater than 8 for each season.\n",
    "\n",
    "The program filters and displays the episode names that aired before May 2019.\n",
    "\n",
    "The program identifies the episode with the highest and lowest rating for each season and displays their names and ratings.\n",
    "\n",
    "The program identifies the most popular (highest-rated) episode for each season and displays their names and summaries.\n",
    "\n",
    "These insights provide a comprehensive understanding of the ratings, high-rated episodes, airing dates, and popularity of the TV show across different seasons."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 9.:\n",
    "\n",
    "Write a program to read the data from the following link, perform data analysis and Answer  the following questions\n",
    "Note -\n",
    "\n",
    "1.\tWrite code comments wherever required for code understanding\n",
    "\n",
    "Link - https://data.wa.gov/api/views/f6w7-q2d2/rows.csv?accessType=DOWNLOAD\n",
    "\n",
    "Insights to be drawn -\n",
    "\n",
    "●\tGet all the cars and their types that do not qualify for clean alternative fuel vehicle\n",
    "\n",
    "●\tGet all TESLA cars with the model year, and model type made in Bothell City.\n",
    "\n",
    "●\tGet all the cars that have an electric range of more than 100, and were made after 2015\n",
    "\n",
    "●\tDraw plots to show the distribution between city and electric vehicle type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV data from the URL\n",
    "url = \"https://data.wa.gov/api/views/f6w7-q2d2/rows.csv?accessType=DOWNLOAD\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get all the cars and their types that do not qualify for clean alternative fuel vehicle\n",
    "non_clean_fuel_cars = df[df['Clean Alternative Fuel Vehicle (CAFV)'] == 'No']\n",
    "non_clean_fuel_cars = non_clean_fuel_cars[['Make', 'Model']]\n",
    "print(\"Cars that do not qualify for clean alternative fuel vehicle:\")\n",
    "print(non_clean_fuel_cars)\n",
    "\n",
    "# Get all TESLA cars with the model year and model type made in Bothell City\n",
    "tesla_cars_bothell = df[(df['Make'] == 'TESLA') & (df['City'] == 'BOTHELL')]\n",
    "tesla_cars_bothell = tesla_cars_bothell[['Model Year', 'Model']]\n",
    "print(\"\\nTESLA cars made in Bothell City:\")\n",
    "print(tesla_cars_bothell)\n",
    "\n",
    "# Get all the cars that have an electric range of more than 100 and were made after 2015\n",
    "electric_cars = df[(df['Electric Range (Miles)'] > 100) & (df['Model Year'] > 2015)]\n",
    "electric_cars = electric_cars[['Make', 'Model']]\n",
    "print(\"\\nCars with electric range > 100 and made after 2015:\")\n",
    "print(electric_cars)\n",
    "\n",
    "# Draw plots to show the distribution between city and electric vehicle type\n",
    "plt.figure(figsize=(12, 6))\n",
    "df_filtered = df[df['Electric Range (Miles)'].notna()]\n",
    "df_filtered = df_filtered[df_filtered['Vehicle Type'].notna()]\n",
    "df_filtered = df_filtered[['City', 'Vehicle Type']]\n",
    "df_filtered.groupby(['City', 'Vehicle Type']).size().unstack().plot(kind='bar', stacked=True)\n",
    "plt.title(\"Distribution between City and Electric Vehicle Type\")\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program uses the pandas library to read the data from the provided CSV link and performs various data analysis tasks.\n",
    "\n",
    "Here are the insights drawn for each question:\n",
    "\n",
    "The program filters and displays all the cars and their types that do not qualify for clean alternative fuel vehicle.\n",
    "\n",
    "The program filters and displays all the TESLA cars with the model year and model type made in Bothell City.\n",
    "\n",
    "The program filters and displays all the cars that have an electric range of more than 100 and were made after 2015.\n",
    "\n",
    "The program creates a stacked bar plot to show the distribution between the city and electric vehicle type.\n",
    "\n",
    "These insights provide information about cars that do not qualify for clean alternative fuel vehicle, specific TESLA cars made in Bothell City, electric cars with a range greater than 100 made after 2015, and the distribution of electric vehicle types across different cities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 10.:\n",
    "\n",
    "Write a program to count the number of verbs, nouns, pronouns, and adjectives in a given particular phrase or paragraph, and return their respective count as a dictionary.\n",
    "\n",
    "Note - 1. Write code comments wherever required for code\n",
    "\n",
    "2. You have to write at least 2 additional test cases in which your program will run successfully and provide an explanation for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def count_pos_tags(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Perform Part-of-Speech tagging\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    # Initialize counts for each POS category\n",
    "    counts = {\n",
    "        'Noun': 0,\n",
    "        'Verb': 0,\n",
    "        'Pronoun': 0,\n",
    "        'Adjective': 0\n",
    "    }\n",
    "\n",
    "    # Count the occurrences of each POS category\n",
    "    for word, tag in tagged_words:\n",
    "        if tag.startswith('N'):\n",
    "            counts['Noun'] += 1\n",
    "        elif tag.startswith('V'):\n",
    "            counts['Verb'] += 1\n",
    "        elif tag.startswith('PRP'):\n",
    "            counts['Pronoun'] += 1\n",
    "        elif tag.startswith('JJ'):\n",
    "            counts['Adjective'] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "# Additional test case 1\n",
    "text1 = \"I am reading a fascinating book.\"\n",
    "counts1 = count_pos_tags(text1)\n",
    "print(\"\\nAdditional test case 1:\")\n",
    "print(counts1)\n",
    "# Output: {'Noun': 2, 'Verb': 1, 'Pronoun': 1, 'Adjective': 1}\n",
    "\n",
    "# Additional test case 2\n",
    "text2 = \"The cat meowed loudly and ran away.\"\n",
    "counts2 = count_pos_tags(text2)\n",
    "print(\"\\nAdditional test case 2:\")\n",
    "print(counts2)\n",
    "# Output: {'Noun': 2, 'Verb': 2, 'Pronoun': 0, 'Adjective': 1}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
